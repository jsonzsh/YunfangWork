#coding=utf-8
import scrapy
from scrapy.selector import Selector
from scrapy.contrib.spiders import CrawlSpider,Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.http import Request
from anjuke.items import AnjukeItem
from anjuke.settings import global_spider
from scrapy import log,FormRequest
import re,time,sys,json,MySQLdb,copy
from redis import Redis
from scrapy.http.cookies import CookieJar
from scrapy_redis.spiders import RedisSpider
reload(sys)
sys.setdefaultencoding( "utf-8" )


class anjuke_spider(RedisSpider):
	
	spider_id = global_spider.get_spider_id()
	global_spider.spider_id_add()
	name = "anjuke_spider%s"%spider_id
	redis_key = 'fang_spider:page_url'
	
	allowed_domains = ["fang.com"]


	def parse(self,response):

		sel = Selector(response)
		try:
			links = SgmlLinkExtractor(allow=(r'http://esf.gz.fang.com/.+/.+.htm'),restrict_xpaths=('//dl[@class="list rel"]'),unique=0).extract_links(response)
			r = Redis()
			for link in links:
				try:
					r.lpush('fang_spider:data_url', link.url)
				except Exception as e:
					print Exception,":",e
		except Exception as e:
			print Exception,":",e